#!/usr/bin/env bash

# SPDX-FileCopyrightText: 2021 - 2025 Robin Vobruba <hoijui.quaero@gmail.com>
#
# SPDX-License-Identifier: Unlicense

# See the output of "$0 -h" for details.

# Exit immediately on each error and unset variable;
# see: https://vaneyckt.io/posts/safer_bash_scripts_with_set_euxo_pipefail/
set -Eeuo pipefail
#set -Eeu

script_path="$(readlink -f "${BASH_SOURCE[0]}")"
script_dir="$(dirname "$script_path")"
# shellcheck source=./_common
source "$script_dir/_common"
script_name="$(basename "$(readlink -f "${BASH_SOURCE[0]}")")"

# initial default values
APP_NAME="RDF DB Filler"
BATCH_SIZE_DEFAULT=5000
CLONE_URL_OKH_ONTOLOGY="https://github.com/iop-alliance/OpenKnowHow.git"
CLONE_URL_ODS_ONTOLOGY="https://codeberg.org/elevont/open-dataset.git"
CLONE_URL_OLD_DATA="https://gitlab.opensourceecology.de/verein/projekte/okh/data.git"
CLONE_URL_EXP_DATA="git@github.com:OSEGermany/OKH-data-experimental.git"
CLONE_URL_SAMPLE_DATA="https://gitlab.opensourceecology.de/verein/projekte/okh/data-sample.git"
CLONE_URL_SPDX_LICENSES="https://github.com/spdx/license-list-data.git"
data_url="$CLONE_URL_OLD_DATA"
data_branch="main"
debug_loading=false
cleanup=false
online=true
batch_size="$BATCH_SIZE_DEFAULT"
validate=false
validate_only=false
validation_output_file="$build_dir/ttl_validation_errors.txt"
data_glob="*.ttl"
fraction_tv_proj="-1"
compact=true

function print_help() {

	echo "$APP_NAME - Fills an Apache Jena RDF DB with data from RDF/Turtle files."
	echo
	echo "Usage:"
	echo "  $script_name [OPTION...]"
	echo "Options:"
	echo "  -h, --help"
	echo "    Print this usage help and exit"
	echo "  --debug-loading"
	echo "    Instead of a nice progress bar when loading the data into the DB,"
	echo "    this shows the raw output."
	echo "  --validate"
	echo "    Validate the RDF input files before loading them into the DB"
	echo "    (output: '$validation_output_file')"
	echo "  --validate-only"
	echo "    Validate the RDF input files and exit"
	echo "    (output: '$validation_output_file')"
	echo "  --batch-size <NUMBER>"
	echo "    The number of Turtle files to load into the DB at once"
	echo "    [default: $BATCH_SIZE_DEFAULT]"
	echo "  --offline"
	echo "    Do not try to fetch git repos"
	echo "  --combined-only"
	echo "    Do not load all TTL files, only ones that have the string 'combined'"
	echo "    in their file-name"
	echo "  --skip-compacting"
	echo "    Do not compact the DB after loading 100k projects"
	echo "  --thingiverse-fraction <FRACTION>"
	echo "    Do not load all the date from Thingiverse.com, but only the newest part"
	echo "  --experimental"
	echo "    Uses the new experimental data source."
	echo "    NOTE: This data is private, so you need to get access first"
	echo "  --custom-data <GIT-REPO-URL> <BRANCH>"
	echo "    Uses the given git reoo and branch as the data-source."
	echo "    Please use an HTTP(S) git URL without the need for authentification."
	echo "  --local-data <DIR>"
	echo "    Uses the given local directory as the data-source."
	echo "  --samples"
	echo "    Uses the a tiny set of sample data plus the ontology."
	echo "Examples:"
	echo "  $script_name"
	echo "  $script_name --help"
	echo "  $script_name --experimental"
	echo "  $script_name --custom-data \"$CLONE_URL_OLD_DATA\" main"
	echo "  $script_name --local-data /data --batch-size 1000"
	echo "  $script_name --samples"
	echo "  $script_name --validate --samples"
	echo "  $script_name --local-data /data --thingiverse-fraction 0.2"
}

# read command-line args
POSITIONAL=()
while [[ $# -gt 0 ]]
do
	arg="$1"
	shift # $2 -> $1, $3 -> $2, ...

	case "$arg" in
		-h|--help)
			print_help
			exit 0
			;;
		--debug-loading)
			debug_loading=true
			;;
		--validate)
			validate=true
			;;
		--validate-only)
			validate=true
			validate_only=true
			;;
		--batch-size)
			batch_size="$1"
			shift
			;;
		-o|--offline)
			online=false
			;;
		--combined-only)
			data_glob="*combined*.ttl"
			;;
		--skip-compacting)
			compact=false
			;;
		--thingiverse-fraction)
			fraction_tv_proj="$1"
			shift
			;;
		--experimental)
			data_url="$CLONE_URL_EXP_DATA"
			;;
		--custom-data)
			data_url="$1"
			shift
			data_branch="$1"
			shift
			;;
		--local-data)
			data_url=""
			data_branch=""
			data_dir="$1"
			shift
			;;
		--samples)
			data_url="$CLONE_URL_SAMPLE_DATA"
			data_branch="master"
			;;
		*) # non-/unknown option
			POSITIONAL+=("$arg") # save it in an array for later
			;;
	esac
done
set -- "${POSITIONAL[@]}" # restore positional parameters

function repo_ensure_latest() {
	dir="$1"
	clone_url="$2"
	main_branch="${3:-master}"
	mkdir -p "$(dirname "$dir")"
	if [ -d "$dir" ]
	then
		if $online
		then
			git -C "$dir" fetch origin "$main_branch"
			git -C "$dir" rebase "origin/$main_branch"
		fi
	else
		if ! $online
		then
			>&2 echo "ERROR: --offline chosen and repo '$dir' not present!"
			exit 1
		fi
		git clone "$clone_url" --single-branch "$dir"
	fi
}

function compact_db() {
	if $compact
	then
		echo "Compacting the DB ..."
		"$jena_db_data_compactor" \
			--loc "$db_tmp_dir"
		# Remove old data dir(s)
		find "$db_tmp_dir" -maxdepth 1 -name "Data-*" \
			| sort \
			| head -n -1 \
			| xargs rm -Rf
		echo "Compacting the DB - done."
	fi
}

ensure_java_version
ensure_tool "$JENA_HOME" "$JENA_DL_URL" "Apache Jena"

echo
echo "Get/Update input RDF ..."

ontologies_dir="$HOME/.local/cache/onts"
for clone_url_ont in "$CLONE_URL_ODS_ONTOLOGY" "$CLONE_URL_OKH_ONTOLOGY"
do
	ont_dir_name="$(basename --suffix ".git" "$clone_url_ont")"
	ont_dir="$ontologies_dir/$ont_dir_name"
	repo_ensure_latest "$ont_dir" "$clone_url_ont" "master" \
		|| repo_ensure_latest "$ont_dir" "$clone_url_ont" "main"
done

spdx_licenses_dir="$ontologies_dir/spdx-$(basename --suffix ".git" "$CLONE_URL_SPDX_LICENSES")"
if ! [ -e "$spdx_licenses_dir" ]
then
	# This only fetches the objects for the latest commit. -> GoooooD
	git clone --no-checkout --filter=blob:none "$CLONE_URL_SPDX_LICENSES" "$spdx_licenses_dir"

	# This fetches all objects. -> BAD!
# 	mkdir -p "$spdx_licenses_dir"
# 	git -C "$spdx_licenses_dir" init
# 	git -C "$spdx_licenses_dir" remote add -f origin "$CLONE_URL_SPDX_LICENSES"

	git -C "$spdx_licenses_dir" config core.sparseCheckout true
	echo "rdfturtle/" >> "$spdx_licenses_dir/.git/info/sparse-checkout"
	git -C "$spdx_licenses_dir" checkout main
fi
git -C "$spdx_licenses_dir" pull --depth 1 --rebase --force

ontology_ttls_root="$ontologies_dir"

if [ -z "$data_url" ]
then
	data_ttls_root="$data_dir"
else
	mkdir -p "$data_dir"
	data_slug_parent="$(basename "$(dirname "$data_url")")"
	data_slug_repo="$(basename --suffix ".git" "$data_url")"
	data_dir_name="${data_slug_parent}__$data_slug_repo"
	projs_data_dir="$data_dir/$data_dir_name"
	repo_ensure_latest "$projs_data_dir" "$data_url" "$data_branch"
	data_ttls_root="$projs_data_dir"
fi

if $cleanup
then
	echo
	echo "Checking file-names ..."
	find \
		"$data_ttls_root" -type f -name "*.ttl" \
		| while read -r file
	do
		no_spaces_file="${file// /_}"

		if [ "$no_spaces_file" != "$file" ]
		then
			>&2 echo "ERROR: File-name with spaces detected, please rename: '$file'"
			exit 2
		fi
	done

	echo
	echo "Fixing the data from the Krawler ..."
	find \
		"$data_ttls_root" -type f -name "*.ttl" \
		-name "*.ttl" \
		| while read -r ttl_file
	do
		echo "    '$ttl_file' ..."
		sed -i \
			-e 's|^@base\(.*\)#> .$|@base\1> .\n@prefix :         <#> .|' \
			"$ttl_file"
	done
fi

echo
echo "Setting up the DB in '$db_dir' (temp dir: '$db_tmp_dir') ..."
echo "    loading from '$ontology_ttls_root'"
echo "    loading from '$data_ttls_root'"

input_list_file_base="/tmp/inputs_$RANDOM"
input_list_file="$input_list_file_base.csv"
input_list_file_tv="${input_list_file_base}_thingiverse.csv"
echo
echo "Assembling the list of RDF source files ..."
find \
	"$ontology_ttls_root" \
	-name "*.ttl" \
	> "$input_list_file"
if [ "$fraction_tv_proj" != "-1" ]
then
	find \
		"$data_ttls_root" \
		-name "$data_glob" \
		| grep -v thingiverse.com \
		>> "$input_list_file"
	find \
		"$data_ttls_root" \
		-name "$data_glob" \
		| grep thingiverse.com \
		| sort \
		>> "$input_list_file_tv"
	num_inputs_tv="$(wc -l < "$input_list_file_tv")"
	echo "Thingiverse.com projects total: $num_inputs_tv"
	num_tv_projs=$(echo "$num_inputs_tv" | awk '{printf("%d\n", ('"$fraction_tv_proj"' * $1) + 0.5)}')
	echo "Thingiverse.com projects selected: $num_tv_projs"
	tail -n "-$num_tv_projs" \
		< "$input_list_file_tv" \
		>> "$input_list_file"
else
	find \
		"$data_ttls_root" \
		-name "$data_glob" \
		>> "$input_list_file"
fi
num_inputs="$(wc -l < "$input_list_file")"
echo "# input files: $num_inputs"

if $validate
then
	echo
	echo "Validating input files syntax ..."
	rm -Rf "$validation_output_file"
	touch "$validation_output_file"
	time while mapfile -t -n "$batch_size" batch && ((${#batch[@]}))
	do
		"$jena_db_data_validator" \
			--validate \
			"${batch[@]}" \
			|| true 2>&1 \
			| grep -v INFO -B 1 \
			| tee --append "$validation_output_file"
	done < "$input_list_file" 2>&1 \
		| pv -pet --line-mode --size "$num_inputs" > /dev/null
	echo "Validation results stored in file '$validation_output_file'."
	lines_syntax_violations="$(cat "$validation_output_file" | wc -l)"
	num_syntax_violations="$((lines_syntax_violations / 2))"
	echo "# of Turtle syntax violations: $num_syntax_violations"
	if [ "$num_syntax_violations" -gt 0 ]
	then
		echo
		echo "There are syntax violations -> (non-zero-)exiting"
		exit 1
	fi
	if $validate_only
	then
		echo
		echo "done."
		exit 0
	fi
fi

rm -Rf "$db_tmp_dir"
mkdir -p "$db_tmp_dir"

echo
echo "Loading data into the DB in batches of size $batch_size ..."
batch_idx=1
if $debug_loading
then
	time while mapfile -t -n "$batch_size" batch && ((${#batch[@]}))
	do
		"$jena_db_data_injector" \
			--loc "$db_tmp_dir" \
			"${batch[@]}"
	#		--loader=parallel \
		if [ $((batch_idx % 20)) -eq 0 ]
		then
			compact_db
		fi
		batch_idx=$((batch_idx + 1))
	done < "$input_list_file"
else
	time while mapfile -t -n "$batch_size" batch && ((${#batch[@]}))
	do
		"$jena_db_data_injector" \
			--loc "$db_tmp_dir" \
			"${batch[@]}"
	#		--loader=parallel \
		if [ $((batch_idx % 20)) -eq 0 ]
		then
			compact_db
		fi
		batch_idx=$((batch_idx + 1))
	done < "$input_list_file" 2>&1 \
		| pv -pet --line-mode --size "$num_inputs" > /dev/null
fi
compact_db
echo
if [ -e "$db_dir" ]
then
	echo "Moving the current DB to the backup location '$db_bak_dir' ..."
	rm -Rf "$db_bak_dir"
	mv "$db_dir" "$db_bak_dir"
	echo "Moving the current DB to the backup location '$db_bak_dir' - done."
fi
echo "Moving the new/temporary DB to the active location at '$db_dir' ..."
mv "$db_tmp_dir" "$db_dir"
echo "Moving the new/temporary DB to the active location at '$db_dir' - done."

echo
echo "Ready to run SPARQL queries!"
echo
echo "for example:"
echo "$jena_db_data_querier \\"
echo "    --loc \"$db_dir\" \\"
echo "    --query \"$res_dir/sample-queries/list-projects.sparql\""
echo
echo "Or start the Web interface for running SPARQL queries with:"
echo "run/web-ui"
echo
echo "done."
